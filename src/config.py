
# ===============================================================
# CELL 4: CONFIG - V36 (Single-Stream Bidirectional Mamba)
# ===============================================================
import os
# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True' # Báº­t náº¿u cáº§n
import torch
import random
import numpy as np

class Config:
    # ============ DATA & PATHS (HAM10000) ===========
    CSV_FILE = "/home/ibmelab/Documents/skin/skin-cancer-mnist-ham10000/HAM10000_metadata.csv"
    IMG_ROOTS = [
        "/home/ibmelab/Documents/skin/skin-cancer-mnist-ham10000/HAM10000_images_part_1", 
        "/home/ibmelab/Documents/skin/skin-cancer-mnist-ham10000/HAM10000_images_part_2",
    ]
    OUTPUT_DIR = "/home/ibmelab/Documents/G_MMNet/checkpoints"
    
    # ðŸ”¥ KHÃ”NG DÃ™NG RESUME - Train tá»« Ä‘áº§u
    RESUME_CHECKPOINT = None 
    
    # ðŸ”¥ CHá»ˆ Äá»ŠNH GPU 1
    DEVICE = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")
    
    SEED = 42
    N_SPLITS = 5
    
    # ============ MODEL ARCHITECTURE (V36 - Single Stream Lite) ===========
    NUM_CLASSES = 7
    IMG_SIZE = 224            # Giá»¯ 224x224 cho an toÃ n vÃ  nhanh
    META_DIM = 256
    
    # CÃ¡c tham sá»‘ nÃ y khÃ´ng cÃ²n dÃ¹ng cho V36 (vÃ¬ V36 tá»± Ä‘á»‹nh nghÄ©a D_MODEL=512)
    # NhÆ°ng cá»© Ä‘á»ƒ Ä‘Ã¢y Ä‘á»ƒ trÃ¡nh lá»—i náº¿u cÃ³ code cÅ© gá»i tá»›i
    IMG_EMBED_DIM_FINE = 192  
    IMG_EMBED_DIM_COARSE = 768 
    FUSION_MLP_DIM_FINE = 768    
    FUSION_MLP_DIM_COARSE = 3072
    FUSION_NUM_LAYERS = 4
    FUSION_NUM_HEADS = 8    
    USE_CROSS_SCALE = False   # V36 lÃ  Single Stream, khÃ´ng cáº§n Cross Scale
    
    # ============ REGULARIZATION (V36 - á»”n Ä‘á»‹nh) ===========
    META_DROPOUT = 0.15
    FUSION_DROPOUT = 0.15
    META_FEATURE_DROPOUT_RATE = 0.1
    MODALITY_DROPOUT_RATE = 0.15
    STOCHASTIC_DEPTH_RATE = 0.05 # Má»©c ráº¥t nháº¹
    
    # ============ TRAINING (Tá»‘i Æ°u tá»‘c Ä‘á»™) ===========
    BATCH_SIZE = 16       # â¬†ï¸ TÄƒng lÃªn 16 (VÃ¬ V36 nháº¹ hÆ¡n V35)
    EPOCHS = 200 
    PATIENCE = 200
    FOLDS_TO_RUN = [0,1,2,3,4]
    
    # ============ LOSS & STRATEGY ===========
    USE_HYBRID_LOSS = False    
    LABEL_SMOOTHING = 0.05
    USE_FOCAL_LOSS = True 
    FOCAL_LOSS_GAMMA = 2.0 
    
    # ============ OPTIMIZER ===========
    WEIGHT_DECAY = 0.05       
    BETAS = (0.9, 0.999)    
    EPS = 1e-6
    
    # ============ LEARNING RATE (An toÃ n) ===========
    HEAD_LR = 5e-5            # Giá»¯ má»©c 1e-4 Ä‘á»ƒ trÃ¡nh NaN
    BACKBONE_LR = 5e-6        
    
    # ============ SCHEDULER ===========
    SCHEDULER_TYPE = 'cosine' 
    WARMUP_EPOCHS = 15        
    
    # ============ AUGMENTATION (Táº¯t Mixup Ä‘á»ƒ dÃ¹ng Masking) ===========
    USE_TTA = True
    USE_MIXUP = False 
    MIXUP_PROB = 0.5 
    MIXUP_ALPHA = 0.4
    
    # ============ CONSISTENCY LOSS (V36 - Masking) ===========
    USE_AMP = False           # Táº¯t AMP (FP32) Ä‘á»ƒ trÃ¡nh NaN tuyá»‡t Ä‘á»‘i
    GRAD_CLIP = 0.5           
    USE_MASKING_LOSS = True   # âœ… Báº­t Masking Consistency
    MASKING_RATIO = 0.3  
    MASKING_LOSS_WEIGHT = 1.0 
    
cfg = Config()

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)

print(f"\nâœ… Config V36 (Single-Stream Bidirectional + Masking) Ready:")
print(f"   ðŸ”¥ GPU: {cfg.DEVICE}")
print(f"   Model: DenseNet121 -> Single Stream Mamba (512D)")
print(f"   Strategy: Masking Loss (15%) | FP32 | Batch={cfg.BATCH_SIZE}")